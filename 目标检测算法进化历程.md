# 目标检测进化历程

## RCNN

创新点：第一次将CNN引入到了目标检测领域。

流程：

- 用selective search找到2000个候选边框。
- 对每个边框，放缩到固定大小，然后用CNN提取出特征，保存在磁盘中。
- 用SVM对这2000个边框的特征进行分类。
- NMS筛选掉多余的边框。
- 通过边框回归技术来微调边框。

RCNN是multi-stage的，因为整个训练过程分为四个部分：

- 先用selective search找到2000个候选边框。
- 训练CNN。提取特征用的是AlexNet，即5个卷积层和2个全连接层，最后再加一个SoftMax分类层。再利用规则1(**IOU > 0.5为正样  
  本，否则为负样本**)为这2000个边框分配类别标签。然后就利用这些有标签的数据去训练。
- 使用规则2(**包含整个物体的边框作为正样本，IOU < 0.3的作为负样本**)从2000个候选框中挑选出正负样本，将conv5作为输入的  
  特征，为每个类别训练一个SVM分类器。
- 利用conv5的特征，为每个类别训练边框回归。

疑问：为什么CNN已经有了SoftMax层，还要单独训练一个SVM分类器呢？

答案：因为CNN的SoftMax层没有单独训练的SVM分类器准确率高。在训练的时候，我们认为IOU > 0.5的就是正样本，实际上这个标准太  
宽松了。但是这个标准必须这么宽松，因为CNN很容易过拟合，所以训练的时候需要大量的数据，宽松的标准能够使我们得到更多的正样本用  
来训练。训练数据本身的不准确就导致了最后的SoftMax分类器准确率不高。为了得到更准确的分类结果，需要单独训练SVM分类器。我们注  
意到规则2要比规则1更严格，所以得到的训练数据质量更高，SVM的准确度也就比SoftMax更高。规则2更严格就会导致训练数据变少，会对  
SVM的训练有影响吗？答案是不会，因为SVM本身就比较适合小样本学习。

缺点：

- multi-stage，训练缓慢。
- 没有共享计算，每个边框都要用CNN提取一遍特征。对于那些有很多重叠的边框，计算资源就会被白白浪费。

## SPPNet

SPPNet是RCNN的优化版本。

创新点：

- 不用每个RoI都提取一遍特征，而是先提取出整幅图片的特征，然后再截取出对应RoI的特征即可。
- RCNN中对于RoI的放缩会使图像产生形变，SPPNet中使用SPP层解决这个问题。

缺点：

- 整个过程还是multi-stage的。
- 没法更新SPP前面的卷积层(原因暂时不懂)。

## Fast-RCNN

创新点：

- 将SVM分类器和边框回归器合并到CNN中，如果不看selective search，整个网络是single-stage的。
- 训练的时候能更新所有层，这点是针对SPPNet说的。
- 提出了RoIPool层，本质上是SPP的特例。

缺点：selective search还没有集成到网络中来。

## Faster-RCNN

创新点：提出了Region Proposal Network替代selective search，整个网络是single-stage的

缺点：共享计算只发生在RoIPool层之前，RoIPool之后仍然是对每个RoI分别提取特征，没有实现完全的共享计算。

## RFCN

提出了平移不变性和平移可变性。平移不变性是指，图片中的物体发生了平移，但是图片的feature map不变。平移不变性的网络适合分类，  
即便图片发生了平移、形变，但是最后的分类的结果不会变。平移可变性的网络适合目标检测，物体的位置发生了改变，预测的边框相对应的  
也会发生变化。

平移不变性感受野有关系，如果feature map每个点的感受野越大，则这个feature map的平移不变性越好。举个例子，现在要统计整个  
河南省的平均体重，现在一个男生胖了五十斤，对于最后的统计结果是不会有什么影响的。但是如果是统计这个男生家庭的平均体重，他就会  
产生很大的影响了。

随着网络的加深，N多层pooling之后，feature map越来越小，每个点对应的感受野越来越大，此时图片中这个感受野内小幅度的平移根  
本不会被feature map感知到。ResNet101层次很深，平移可变性很差，但是为什么基于ResNet101的Faster-RCNN效果却很好呢。这  
是因为RoIPooling层这种逐proposal操作的方式为ResNet101网络带来了平移可变性。

RPN使用的feature map还不是很小，所以平移可变性还是不错的。这个时候图片中的微小平移会被输入到RPN的feature map感知到。  
所以RPN输出的proposals会发生变化。如果我们把每个proposal看成一幅新的图片，RoIPooling之后的层相当于在为这些新的图片分  
别提取**平移不变的特征**。这个时候平移不变的特征反而变成好事了，它使我们能更准确的判断每个proposal的类别。所以虽然RoIPooling  
层之后仍然在提取平移不变的特征，但是RoIPooling层这种对每个proposal分别提取特征的方式就破坏了整个网络的平移不变性，引入了  
平移可变性。

RFCN的初衷是为了加快FasterRCNN的速度。FasterRCNN中RoIPooling层之前已经实现了共享计算，但是之后还是相当于对每个proposals  
分别提取特征，没有实现完全的共享计算。所以RFCN想到把RoIPooling移到最后一层，虽然速度提高了，但是发现mAP降低了很多。实验  
发现RoIPooling在最后一层的mAP是68.9%，而本来的FasterRCNN是76.4%。这是因为RoIPooling被放到了最后一层，无法为网络带  
来平移可变性。所以为了弥补平移可变性的缺失，RFCN提出了position sensitive score map来产生具备平移可变性的feature map。

创新点：

- 提出position sensitive score map，为网络增加了平移可变性。
- 把RoIPooling放到网络的最后，在不影响准确率的基础上加快了检测的速度。

## FPN

FPN的初衷是想提高FasterRCNN小物体检测的准确率。FasterRCNN使用的是最后一层的feature map，但是最后一层的feature map  
分辨率太低，包含的是很高层次的语义信息，对细节不敏感，不适合小目标检测。

FPN设计了一种提取多尺度特征的方法：用下一层低分辨率高语义的特征加上上一层高分辨率多细节的特征。这样一来网络提取出来的特征就  
同时具备了上下两层的优点。

然后将每一个尺度的特征都输入到RPN网络中产生proposals。RoIPooling的时候，大的proposal用分辨率较小的feature map，小  
的proposal用分辨率较大的feature map。这是因为分辨率大的feature map能保留更多的细节，适合预测小物体。

FPN的中心思想就是：检测大物体用分辨率低的feature map，检测小物体用分辨率高的feature map。

为什么要将每个尺度的特征都送入RPN网络？因为原始的FasterRCNN的RPN网络产生的proposals都太大，检测小物体需要更小的proposals。  
而产生更小的proposals需要高分辨率的feature map。所以就想到高分辨率feature map + RPN -> 小proposals，低分辨率feature  
map + RPN -> 大proposals

## MaskRCNN

MaskRCNN的主要贡献就是设计出了RoIAlign，以及添加了一个额外的FCN分支来预测mask。
